# Option 2: Batch-Based Parallel Processing System
## Project Structure for Future Implementation

**Status**: Design Complete - Ready for Implementation
**Architecture**: Batch-based parallel processing with 6√ó performance improvement
**Code Preservation**: 100% - extract.go, convert.go, store.go unchanged

---

## üìÅ Folder Structure

```
option2-project/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ extraction/
‚îÇ       ‚îú‚îÄ‚îÄ extract/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ extract.go           ‚úÖ PRESERVED - Do not modify
‚îÇ       ‚îú‚îÄ‚îÄ convert/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ convert.go           ‚úÖ PRESERVED - Do not modify
‚îÇ       ‚îú‚îÄ‚îÄ store.go                 ‚úÖ PRESERVED - Do not modify
‚îÇ       ‚îú‚îÄ‚îÄ pass.txt                 Password list (shared)
‚îÇ       ‚îî‚îÄ‚îÄ files/                   Template structure (copied to each batch)
‚îÇ           ‚îú‚îÄ‚îÄ all/                 Archives for extraction
‚îÇ           ‚îú‚îÄ‚îÄ txt/                 Direct TXT files
‚îÇ           ‚îú‚îÄ‚îÄ pass/                Extracted files
‚îÇ           ‚îú‚îÄ‚îÄ nopass/              Password-protected archives
‚îÇ           ‚îî‚îÄ‚îÄ errors/              Extraction errors
‚îÇ
‚îú‚îÄ‚îÄ batches/                         üîÑ AUTO-MANAGED - Batch workspaces created dynamically
‚îÇ   ‚îú‚îÄ‚îÄ batch_001/                  (Example structure - created at runtime)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/extraction/files/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep
‚îÇ
‚îú‚îÄ‚îÄ downloads/                       üì• Temporary download storage
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep
‚îÇ
‚îú‚îÄ‚îÄ archive/                         üóÑÔ∏è Failed batch archive (7-day retention)
‚îÇ   ‚îî‚îÄ‚îÄ failed/
‚îÇ       ‚îî‚îÄ‚îÄ .gitkeep
‚îÇ
‚îú‚îÄ‚îÄ coordinator/                     üéØ TO BE IMPLEMENTED
‚îÇ   ‚îú‚îÄ‚îÄ main.go
‚îÇ   ‚îú‚îÄ‚îÄ config.go
‚îÇ   ‚îú‚îÄ‚îÄ logger.go
‚îÇ   ‚îú‚îÄ‚îÄ health.go
‚îÇ   ‚îú‚îÄ‚îÄ metrics.go
‚îÇ   ‚îú‚îÄ‚îÄ telegram_receiver.go
‚îÇ   ‚îú‚îÄ‚îÄ download_worker.go
‚îÇ   ‚îú‚îÄ‚îÄ batch_coordinator.go
‚îÇ   ‚îú‚îÄ‚îÄ batch_worker.go
‚îÇ   ‚îú‚îÄ‚îÄ batch_cleanup.go
‚îÇ   ‚îú‚îÄ‚îÄ crash_recovery.go
‚îÇ   ‚îî‚îÄ‚îÄ admin_commands.go
‚îÇ
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îî‚îÄ‚îÄ migrations/                 SQL migration files
‚îÇ       ‚îú‚îÄ‚îÄ 001_create_download_queue.sql
‚îÇ       ‚îú‚îÄ‚îÄ 002_create_batch_processing.sql
‚îÇ       ‚îú‚îÄ‚îÄ 003_create_batch_files.sql
‚îÇ       ‚îî‚îÄ‚îÄ 004_create_metrics.sql
‚îÇ
‚îú‚îÄ‚îÄ logs/                           üìù System logs
‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep
‚îÇ
‚îú‚îÄ‚îÄ scripts/                        üîß Operational scripts
‚îÇ   ‚îú‚îÄ‚îÄ migrate.sh
‚îÇ   ‚îú‚îÄ‚îÄ setup.sh
‚îÇ   ‚îî‚îÄ‚îÄ cleanup.sh
‚îÇ
‚îú‚îÄ‚îÄ tests/                          üß™ Test suites
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îî‚îÄ‚îÄ load/
‚îÇ
‚îú‚îÄ‚îÄ monitoring/                     üìä Monitoring configuration
‚îÇ   ‚îú‚îÄ‚îÄ prometheus.yml
‚îÇ   ‚îú‚îÄ‚îÄ prometheus-alerts.yml
‚îÇ   ‚îî‚îÄ‚îÄ dashboards/
‚îÇ       ‚îî‚îÄ‚îÄ telegram-bot.json
‚îÇ
‚îú‚îÄ‚îÄ docs/                           üìö Additional documentation
‚îÇ   ‚îî‚îÄ‚îÄ RUNBOOK.md (to be created in Phase 7)
‚îÇ
‚îú‚îÄ‚îÄ .env.example                    üîê Environment template
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ go.mod
‚îú‚îÄ‚îÄ go.sum
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ checksums.txt                   ‚úÖ Verification file for preserved code
‚îî‚îÄ‚îÄ README.md                       üìñ This file
```

---

## üéØ Purpose

This folder contains the **complete project structure** for Option 2 implementation. It includes:

1. **Preserved Code Files**: extract.go, convert.go, store.go (100% unchanged)
2. **Template Directory Structure**: Ready for batch processing
3. **Implementation Blueprint**: Follow the implementation plan to build coordinator

---

## üìã Prerequisites for Implementation

### Required Software
- **Go 1.21+**: For building the coordinator service
- **PostgreSQL 14+**: Database for persistent queues and task tracking
- **Docker & Docker Compose**: For Local Bot API Server and development environment
- **Telegram Bot Token**: With Local Bot API Server configured for 4GB file support
- **Git**: Version control

### Required Credentials
- Telegram Bot Token (store in `.env`)
- Admin Telegram User IDs (comma-separated in `.env`)
- PostgreSQL credentials

---

## üöÄ Quick Start Guide

### Step 1: Initial Setup

```bash
# Navigate to this directory
cd docs/option2-project

# Create .env file from template
cp ../../docs/option2-implementation-plan.md .  # Reference for .env structure
# Edit .env with your values

# Verify preserved code files
ls -lh app/extraction/extract/extract.go
ls -lh app/extraction/convert/convert.go
ls -lh app/extraction/store.go

# Compute checksums for verification
sha256sum app/extraction/extract/extract.go > checksums.txt
sha256sum app/extraction/convert/convert.go >> checksums.txt
sha256sum app/extraction/store.go >> checksums.txt
echo "‚úÖ Checksums saved to checksums.txt"
```

### Step 2: Follow Implementation Plan

The implementation is divided into **7 phases over 12 weeks**:

**Phase 1 (Week 1-2)**: Foundation
- Database schema creation
- Configuration management
- Logging framework
- Health & metrics endpoints

**Phase 2 (Week 3-4)**: Download Pipeline
- Telegram bot receiver
- Download worker pool (3 concurrent)
- SHA256 hash computation
- Crash recovery

**Phase 3 (Week 5-6)**: Batch Coordinator
- Batch creation logic
- Directory structure generation
- File routing (archives ‚Üí all/, TXT ‚Üí txt/)
- Max concurrent batch enforcement

**Phase 4 (Week 7-8)**: Batch Processing Workers
- Batch worker pool (5 concurrent)
- Extract ‚Üí Convert ‚Üí Store pipeline
- Working directory management
- Batch cleanup service

**Phase 5 (Week 9)**: Admin Commands
- `/queue`, `/batches`, `/stats`, `/health` commands
- Real-time statistics from PostgreSQL

**Phase 6 (Week 10-11)**: Testing & Optimization
- Unit tests, integration tests, load tests
- Performance profiling and optimization

**Phase 7 (Week 12)**: Documentation & Deployment
- Docker Compose & Kubernetes setup
- Grafana dashboards
- Runbook and operational procedures

---

## üìö Documentation References

**Complete documentation is located in the parent `docs/` directory:**

### Design Documents
- **`option2-prd.md`**: Product Requirements Document
  - Business objectives and success metrics
  - Functional and non-functional requirements
  - Database schema and API specifications

- **`option2-batch-parallel-design.md`**: Detailed Architecture Design
  - Batch directory structure and isolation
  - Working directory pattern for code preservation
  - Performance analysis and timeline comparisons

- **`option2-implementation-plan.md`**: Phase-by-Phase Implementation Guide (Part 1)
  - Phases 1-3: Foundation, Download Pipeline, Batch Coordinator
  - Detailed code implementations for each component

- **`option2-implementation-plan-part2.md`**: Implementation Guide (Part 2)
  - Phases 4-7: Batch Workers, Admin Commands, Testing, Deployment
  - Monitoring, rollback plans, and troubleshooting
  - Prompts for Claude Code

### Implementation Order

```
1. Read: option2-prd.md (understand requirements)
2. Read: option2-batch-parallel-design.md (understand architecture)
3. Follow: option2-implementation-plan.md (Phase 1-3)
4. Follow: option2-implementation-plan-part2.md (Phase 4-7)
5. Use: Prompts from Section 9 of Part 2 for Claude Code assistance
```

---

## ü§ñ Using Claude Code for Implementation

### Recommended Approach

**Use the prompts from `option2-implementation-plan-part2.md` Section 9** to guide Claude Code through implementation. Each prompt is designed for a specific phase:

#### Phase 1: Foundation Setup
```
Use Prompt 9.2 from option2-implementation-plan-part2.md

This will implement:
- Config management
- Logger initialization
- Health check endpoint
- Metrics endpoint
- Main entry point skeleton
```

#### Phase 2: Download Pipeline
```
Use Prompt 9.3 from option2-implementation-plan-part2.md

This will implement:
- Telegram bot receiver
- Download worker pool
- SHA256 hash computation
- Crash recovery
```

#### Phase 3: Batch Coordinator
```
Use Prompt 9.4 from option2-implementation-plan-part2.md

This will implement:
- Batch creation logic
- Directory structure generation
- File routing
```

#### Phase 4: Batch Workers
```
Use Prompt 9.5 from option2-implementation-plan-part2.md

CRITICAL: This phase executes extract.go, convert.go, store.go
The prompt ensures code preservation through working directory changes.
```

#### Subsequent Phases
Continue with Prompts 9.6, 9.7, 9.8 for Admin Commands, Testing, and Deployment.

---

## ‚ö†Ô∏è Critical Implementation Rules

### Code Preservation (100% Requirement)

**NEVER modify these files:**
- `app/extraction/extract/extract.go`
- `app/extraction/convert/convert.go`
- `app/extraction/store.go`

**Verification**:
```bash
# After ANY changes, verify checksums match
sha256sum -c checksums.txt

# Expected output:
# app/extraction/extract/extract.go: OK
# app/extraction/convert/convert.go: OK
# app/extraction/store.go: OK
```

If checksums don't match, **REVERT IMMEDIATELY** and restore from backup.

### Worker Concurrency Limits

**Fixed Limits (NEVER CHANGE)**:
- **Download Workers**: Exactly 3 (Telegram API rate limit)
- **Batch Workers**: Maximum 5 (configurable, but tested at 5)

**Reason**: Extract and convert process entire directories. Multiple workers on the same directory cause race conditions and corruption.

### Batch Processing Pattern

**Working Directory Approach**:
```go
// CORRECT: Change working directory before execution
originalWD, _ := os.Getwd()
defer os.Chdir(originalWD)  // Always restore

os.Chdir("batches/batch_001")  // Change to batch root
exec.Command("go", "run", "../../app/extraction/extract/extract.go")  // Relative path to preserved code
```

**Why this works**:
- extract.go processes files in `app/extraction/files/all/` (relative to working directory)
- By changing to `batches/batch_001/`, extract.go processes `batches/batch_001/app/extraction/files/all/`
- Code remains 100% unchanged

---

## üß™ Testing Strategy

### Unit Tests
```bash
# Test individual components
go test ./coordinator/...

# Test with coverage
go test -cover ./coordinator/...
```

### Integration Tests
```bash
# Full pipeline test
go test -v ./tests/integration/...
```

### Load Tests
```bash
# 100 files baseline
go test -v -timeout 3h ./tests/load -run TestLoad100Files

# 1000 files stress test
go test -v -timeout 24h ./tests/load -run TestLoad1000Files
```

### Verification Tests
```bash
# Verify code preservation
sha256sum -c checksums.txt

# Verify worker limits
# Upload files and check: SELECT COUNT(*) FROM download_queue WHERE status='DOWNLOADING';
# Should NEVER exceed 3

# Verify batch isolation
# Check that batch directories are independent
ls -lh batches/
```

---

## üìä Performance Targets

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Processing Time** (100 files) | < 2 hours | End-to-end from upload to completion |
| **Throughput** | ‚â• 50 files/hour | Sustained over 24-hour period |
| **Success Rate** | ‚â• 98% | (Successful / Total) √ó 100 |
| **RAM Usage** | < 20% | Peak during load test |
| **CPU Usage** | < 50% | Sustained average |
| **Concurrent Batches** | Exactly 5 max | Never exceeds MAX_BATCH_WORKERS |

---

## üõ†Ô∏è Common Operations

### Development Mode
```bash
# Start PostgreSQL and Local Bot API
docker-compose up -d postgres local-bot-api

# Run migrations
./scripts/migrate.sh

# Start coordinator in development mode
cd coordinator && go run .
```

### Production Deployment
```bash
# Build Docker image
docker build -t telegram-bot-option2:latest .

# Deploy with Docker Compose
docker-compose up -d

# OR Deploy to Kubernetes
kubectl apply -f k8s/
```

### Monitoring
```bash
# Check health
curl http://localhost:8080/health | jq .

# View metrics
curl http://localhost:9090/metrics

# Grafana Dashboard
open http://localhost:3000
```

### Troubleshooting
```bash
# View coordinator logs
tail -f logs/coordinator.log

# View batch logs
tail -f batches/batch_001/logs/extract.log

# Check queue status via Telegram
# Send /queue to bot

# Check database
psql -U bot_user -d telegram_bot_option2 -c "SELECT * FROM batch_processing WHERE status='FAILED';"
```

---

## üîÑ Migration from Option 1 (If Applicable)

If you currently have Option 1 (sequential processing) deployed:

### Migration Steps

1. **Backup Current System**
   ```bash
   pg_dump -U bot_user current_db > backup.sql
   tar -czf app_backup.tar.gz app/
   ```

2. **Deploy Option 2 in Parallel**
   - Use different database name
   - Use different Telegram bot token (create new bot for testing)
   - Deploy to separate infrastructure

3. **Gradual Migration**
   - Test Option 2 with small file sets
   - Compare results with Option 1
   - Verify data integrity

4. **Cutover**
   - Stop Option 1 bot
   - Point main bot token to Option 2
   - Monitor for 24 hours

5. **Rollback Plan**
   - Keep Option 1 infrastructure for 1 week
   - Ready to revert if critical issues found

---

## üìû Support & Resources

### Documentation
- **PRD**: `../option2-prd.md`
- **Design**: `../option2-batch-parallel-design.md`
- **Implementation Plan Part 1**: `../option2-implementation-plan.md`
- **Implementation Plan Part 2**: `../option2-implementation-plan-part2.md`

### Implementation Assistance
Use the **Prompts for Claude Code** (Section 9 in Part 2) to get step-by-step guidance for each phase.

### Troubleshooting
Refer to **Runbook** (created in Phase 7) for common issues and solutions.

---

## ‚úÖ Implementation Checklist

Track your progress through implementation:

### Setup
- [ ] Reviewed PRD and design documents
- [ ] Set up development environment (Go, PostgreSQL, Docker)
- [ ] Created `.env` file with required values
- [ ] Computed checksums for preserved code files
- [ ] Initialized Git repository

### Phase 1: Foundation (Week 1-2)
- [ ] Database schema created (4 migration files)
- [ ] Config management implemented
- [ ] Logger initialized
- [ ] Health endpoint working
- [ ] Metrics endpoint working
- [ ] Tests passing

### Phase 2: Download Pipeline (Week 3-4)
- [ ] Telegram receiver implemented
- [ ] Download workers implemented (exactly 3)
- [ ] SHA256 hash computation working
- [ ] Crash recovery implemented
- [ ] File uploads working end-to-end

### Phase 3: Batch Coordinator (Week 5-6)
- [ ] Batch creation logic implemented
- [ ] Directory structure created correctly
- [ ] File routing working (archives ‚Üí all/, TXT ‚Üí txt/)
- [ ] Max concurrent batches enforced
- [ ] Batch timeout logic working

### Phase 4: Batch Processing Workers (Week 7-8)
- [ ] Batch workers implemented (max 5)
- [ ] Extract stage working (subprocess execution)
- [ ] Convert stage working (subprocess execution)
- [ ] Store stage working (subprocess execution)
- [ ] Working directory pattern verified
- [ ] **Code preservation verified (checksums match)** ‚úÖ
- [ ] Batch cleanup service working

### Phase 5: Admin Commands (Week 9)
- [ ] `/queue` command working
- [ ] `/batches` command working
- [ ] `/stats` command working
- [ ] `/health` command working
- [ ] All commands admin-only verified

### Phase 6: Testing & Optimization (Week 10-11)
- [ ] Unit tests written and passing
- [ ] Integration tests passing
- [ ] Load test (100 files) < 2 hours
- [ ] Load test (1000 files) maintaining throughput
- [ ] Performance profiling completed
- [ ] Bottlenecks optimized
- [ ] Resource usage within targets

### Phase 7: Documentation & Deployment (Week 12)
- [ ] Docker Compose file created
- [ ] Dockerfile created and tested
- [ ] Kubernetes manifests created
- [ ] Grafana dashboard configured
- [ ] Runbook written
- [ ] Staging deployment successful
- [ ] Production deployment successful
- [ ] Team trained on operations

---

## üéâ Success Criteria

Your Option 2 implementation is successful when:

1. ‚úÖ **Performance**: 100 files processed in < 2 hours
2. ‚úÖ **Code Preservation**: Checksums of extract.go, convert.go, store.go match original
3. ‚úÖ **Reliability**: Success rate > 98% over 1000-file test
4. ‚úÖ **Resource Efficiency**: RAM < 20%, CPU < 50%
5. ‚úÖ **Zero Data Loss**: Crash recovery tests pass with 100% data integrity
6. ‚úÖ **Monitoring**: Grafana dashboards show all metrics
7. ‚úÖ **Operations**: Team can troubleshoot using runbook

---

**Last Updated**: 2025-11-13
**Status**: Ready for Implementation
**Estimated Completion**: 12 weeks from start

For questions or issues, refer to the comprehensive documentation in `../docs/` or use the Claude Code prompts in `option2-implementation-plan-part2.md` Section 9.
